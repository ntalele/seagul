Failure # 1 (occurred at 2020-02-18_16-52-53)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py", line 424, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py", line 377, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.7/dist-packages/ray/worker.py", line 1492, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(KeyError): [36mray::SAC.__init__()[39m (pid=62531, ip=10.1.50.26)
  File "python/ray/_raylet.pyx", line 630, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 637, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 638, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 643, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 623, in function_executor
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 83, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 397, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py", line 172, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 528, in _setup
    self._init(self.config, self.env_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 102, in _init
    self.config["num_workers"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 573, in _make_workers
    logdir=self.logdir)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 60, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 216, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 342, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 778, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy_template.py", line 139, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/dynamic_tf_policy.py", line 134, in __init__
    self.model = make_model(self, obs_space, action_space, config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_policy.py", line 61, in build_sac_model
    twin_q=config["twin_q"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/models/catalog.py", line 280, in get_model_v2
    **model_kwargs)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_model.py", line 74, in __init__
    model_config, name)
  File "/home/grabka/seagul/seagul/rllib/rllib_with_rbf/mlp_net.py", line 25, in __init__
    self.hidden_neurons = model_config["custom_options"]["hidden_neuons"]
KeyError: 'hidden_neuons'

Failure # 2 (occurred at 2020-02-18_16-52-55)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py", line 424, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py", line 377, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.7/dist-packages/ray/worker.py", line 1492, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(KeyError): [36mray::SAC.__init__()[39m (pid=62526, ip=10.1.50.26)
  File "python/ray/_raylet.pyx", line 630, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 637, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 638, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 643, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 623, in function_executor
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 83, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 397, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py", line 172, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 528, in _setup
    self._init(self.config, self.env_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 102, in _init
    self.config["num_workers"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 573, in _make_workers
    logdir=self.logdir)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 60, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 216, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 342, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 778, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy_template.py", line 139, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/dynamic_tf_policy.py", line 134, in __init__
    self.model = make_model(self, obs_space, action_space, config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_policy.py", line 61, in build_sac_model
    twin_q=config["twin_q"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/models/catalog.py", line 280, in get_model_v2
    **model_kwargs)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_model.py", line 74, in __init__
    model_config, name)
  File "/home/grabka/seagul/seagul/rllib/rllib_with_rbf/mlp_net.py", line 25, in __init__
    self.hidden_neurons = model_config["custom_options"]["hidden_neuons"]
KeyError: 'hidden_neuons'

Failure # 3 (occurred at 2020-02-18_16-52-58)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py", line 424, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py", line 377, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.7/dist-packages/ray/worker.py", line 1492, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(KeyError): [36mray::SAC.__init__()[39m (pid=66823, ip=10.1.50.26)
  File "python/ray/_raylet.pyx", line 630, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 637, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 638, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 643, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 623, in function_executor
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 83, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 397, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py", line 172, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 528, in _setup
    self._init(self.config, self.env_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 102, in _init
    self.config["num_workers"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 573, in _make_workers
    logdir=self.logdir)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 60, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 216, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 342, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 778, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy_template.py", line 139, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/dynamic_tf_policy.py", line 134, in __init__
    self.model = make_model(self, obs_space, action_space, config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_policy.py", line 61, in build_sac_model
    twin_q=config["twin_q"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/models/catalog.py", line 280, in get_model_v2
    **model_kwargs)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_model.py", line 74, in __init__
    model_config, name)
  File "/home/grabka/seagul/seagul/rllib/rllib_with_rbf/mlp_net.py", line 25, in __init__
    self.hidden_neurons = model_config["custom_options"]["hidden_neuons"]
KeyError: 'hidden_neuons'

Failure # 4 (occurred at 2020-02-18_16-53-01)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py", line 424, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py", line 377, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.7/dist-packages/ray/worker.py", line 1492, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(KeyError): [36mray::SAC.__init__()[39m (pid=66826, ip=10.1.50.26)
  File "python/ray/_raylet.pyx", line 630, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 637, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 638, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 643, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 623, in function_executor
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 83, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 397, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py", line 172, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 528, in _setup
    self._init(self.config, self.env_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 102, in _init
    self.config["num_workers"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 573, in _make_workers
    logdir=self.logdir)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 60, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 216, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 342, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 778, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy_template.py", line 139, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/dynamic_tf_policy.py", line 134, in __init__
    self.model = make_model(self, obs_space, action_space, config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_policy.py", line 61, in build_sac_model
    twin_q=config["twin_q"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/models/catalog.py", line 280, in get_model_v2
    **model_kwargs)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_model.py", line 74, in __init__
    model_config, name)
  File "/home/grabka/seagul/seagul/rllib/rllib_with_rbf/mlp_net.py", line 25, in __init__
    self.hidden_neurons = model_config["custom_options"]["hidden_neuons"]
KeyError: 'hidden_neuons'

Failure # 5 (occurred at 2020-02-18_16-53-04)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py", line 424, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py", line 377, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.7/dist-packages/ray/worker.py", line 1492, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(KeyError): [36mray::SAC.__init__()[39m (pid=66825, ip=10.1.50.26)
  File "python/ray/_raylet.pyx", line 630, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 637, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 638, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 643, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 623, in function_executor
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 83, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 397, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py", line 172, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 528, in _setup
    self._init(self.config, self.env_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 102, in _init
    self.config["num_workers"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 573, in _make_workers
    logdir=self.logdir)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 60, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 216, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 342, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 778, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy_template.py", line 139, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/dynamic_tf_policy.py", line 134, in __init__
    self.model = make_model(self, obs_space, action_space, config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_policy.py", line 61, in build_sac_model
    twin_q=config["twin_q"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/models/catalog.py", line 280, in get_model_v2
    **model_kwargs)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_model.py", line 74, in __init__
    model_config, name)
  File "/home/grabka/seagul/seagul/rllib/rllib_with_rbf/mlp_net.py", line 25, in __init__
    self.hidden_neurons = model_config["custom_options"]["hidden_neuons"]
KeyError: 'hidden_neuons'

Failure # 6 (occurred at 2020-02-18_16-53-06)
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py", line 424, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py", line 377, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.7/dist-packages/ray/worker.py", line 1492, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(KeyError): [36mray::SAC.__init__()[39m (pid=67106, ip=10.1.50.26)
  File "python/ray/_raylet.pyx", line 630, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 637, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 638, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 643, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 623, in function_executor
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 83, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 397, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py", line 172, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 528, in _setup
    self._init(self.config, self.env_creator)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py", line 102, in _init
    self.config["num_workers"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py", line 573, in _make_workers
    logdir=self.logdir)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 60, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/worker_set.py", line 216, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 342, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/evaluation/rollout_worker.py", line 778, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy_template.py", line 139, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/policy/dynamic_tf_policy.py", line 134, in __init__
    self.model = make_model(self, obs_space, action_space, config)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_policy.py", line 61, in build_sac_model
    twin_q=config["twin_q"])
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/models/catalog.py", line 280, in get_model_v2
    **model_kwargs)
  File "/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/sac/sac_model.py", line 74, in __init__
    model_config, name)
  File "/home/grabka/seagul/seagul/rllib/rllib_with_rbf/mlp_net.py", line 25, in __init__
    self.hidden_neurons = model_config["custom_options"]["hidden_neuons"]
KeyError: 'hidden_neuons'

