{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.60998493 |\n",
      "| ent_coef_loss           | -0.6887871 |\n",
      "| entropy                 | 1.1356977  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 261        |\n",
      "| mean 100 episode reward | -1.36e+03  |\n",
      "| n_updates               | 1700       |\n",
      "| policy_loss             | 43.173332  |\n",
      "| qf1_loss                | 25.247879  |\n",
      "| qf2_loss                | 25.441574  |\n",
      "| time_elapsed            | 6          |\n",
      "| total timesteps         | 1800       |\n",
      "| value_loss              | 0.2410931  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.37886864 |\n",
      "| ent_coef_loss           | -0.7071029 |\n",
      "| entropy                 | 0.8604202  |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 255        |\n",
      "| mean 100 episode reward | -1.24e+03  |\n",
      "| n_updates               | 3700       |\n",
      "| policy_loss             | 82.11292   |\n",
      "| qf1_loss                | 2.6681702  |\n",
      "| qf2_loss                | 2.6097417  |\n",
      "| time_elapsed            | 14         |\n",
      "| total timesteps         | 3800       |\n",
      "| value_loss              | 1.3595394  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.27321556  |\n",
      "| ent_coef_loss           | -0.09798235 |\n",
      "| entropy                 | 0.86794066  |\n",
      "| episodes                | 30          |\n",
      "| fps                     | 262         |\n",
      "| mean 100 episode reward | -1.26e+03   |\n",
      "| n_updates               | 5700        |\n",
      "| policy_loss             | 113.51947   |\n",
      "| qf1_loss                | 3.394276    |\n",
      "| qf2_loss                | 1.9689376   |\n",
      "| time_elapsed            | 22          |\n",
      "| total timesteps         | 5800        |\n",
      "| value_loss              | 1.9490144   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18015426 |\n",
      "| ent_coef_loss           | -0.8810868 |\n",
      "| entropy                 | 0.7982092  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 266        |\n",
      "| mean 100 episode reward | -1.27e+03  |\n",
      "| n_updates               | 7700       |\n",
      "| policy_loss             | 151.18816  |\n",
      "| qf1_loss                | 4.88642    |\n",
      "| qf2_loss                | 3.7005706  |\n",
      "| time_elapsed            | 29         |\n",
      "| total timesteps         | 7800       |\n",
      "| value_loss              | 2.3137016  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.15057054  |\n",
      "| ent_coef_loss           | 0.044304706 |\n",
      "| entropy                 | 0.74573576  |\n",
      "| episodes                | 50          |\n",
      "| fps                     | 266         |\n",
      "| mean 100 episode reward | -1.13e+03   |\n",
      "| n_updates               | 9700        |\n",
      "| policy_loss             | 182.5285    |\n",
      "| qf1_loss                | 517.5196    |\n",
      "| qf2_loss                | 519.78235   |\n",
      "| time_elapsed            | 36          |\n",
      "| total timesteps         | 9800        |\n",
      "| value_loss              | 1.9990288   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.16182192 |\n",
      "| ent_coef_loss           | -0.2687791 |\n",
      "| entropy                 | 0.43454167 |\n",
      "| episodes                | 60         |\n",
      "| fps                     | 257        |\n",
      "| mean 100 episode reward | -984       |\n",
      "| n_updates               | 11700      |\n",
      "| policy_loss             | 193.9472   |\n",
      "| qf1_loss                | 124.83775  |\n",
      "| qf2_loss                | 126.317345 |\n",
      "| time_elapsed            | 45         |\n",
      "| total timesteps         | 11800      |\n",
      "| value_loss              | 1.042868   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.14415495 |\n",
      "| ent_coef_loss           | 0.18151055 |\n",
      "| entropy                 | 0.09644962 |\n",
      "| episodes                | 70         |\n",
      "| fps                     | 260        |\n",
      "| mean 100 episode reward | -904       |\n",
      "| n_updates               | 13700      |\n",
      "| policy_loss             | 189.22983  |\n",
      "| qf1_loss                | 4.798505   |\n",
      "| qf2_loss                | 5.1122904  |\n",
      "| time_elapsed            | 52         |\n",
      "| total timesteps         | 13800      |\n",
      "| value_loss              | 0.6618109  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1560492   |\n",
      "| ent_coef_loss           | -0.31939477 |\n",
      "| entropy                 | 0.24321026  |\n",
      "| episodes                | 80          |\n",
      "| fps                     | 262         |\n",
      "| mean 100 episode reward | -850        |\n",
      "| n_updates               | 15700       |\n",
      "| policy_loss             | 209.98518   |\n",
      "| qf1_loss                | 8.074196    |\n",
      "| qf2_loss                | 7.2489204   |\n",
      "| time_elapsed            | 60          |\n",
      "| total timesteps         | 15800       |\n",
      "| value_loss              | 1.2608464   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.18376397   |\n",
      "| ent_coef_loss           | 0.0025292411 |\n",
      "| entropy                 | 0.4783683    |\n",
      "| episodes                | 90           |\n",
      "| fps                     | 263          |\n",
      "| mean 100 episode reward | -787         |\n",
      "| n_updates               | 17700        |\n",
      "| policy_loss             | 229.1337     |\n",
      "| qf1_loss                | 8.885927     |\n",
      "| qf2_loss                | 8.19923      |\n",
      "| time_elapsed            | 67           |\n",
      "| total timesteps         | 17800        |\n",
      "| value_loss              | 0.74590194   |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19722389 |\n",
      "| ent_coef_loss           | 0.17970693 |\n",
      "| entropy                 | 0.16574371 |\n",
      "| episodes                | 100        |\n",
      "| fps                     | 265        |\n",
      "| mean 100 episode reward | -740       |\n",
      "| n_updates               | 19700      |\n",
      "| policy_loss             | 204.89978  |\n",
      "| qf1_loss                | 14.202667  |\n",
      "| qf2_loss                | 9.535325   |\n",
      "| time_elapsed            | 74         |\n",
      "| total timesteps         | 19800      |\n",
      "| value_loss              | 2.0251732  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.22738831  |\n",
      "| ent_coef_loss           | -0.13714695 |\n",
      "| entropy                 | 0.28571272  |\n",
      "| episodes                | 110         |\n",
      "| fps                     | 264         |\n",
      "| mean 100 episode reward | -628        |\n",
      "| n_updates               | 21700       |\n",
      "| policy_loss             | 212.35562   |\n",
      "| qf1_loss                | 18.130869   |\n",
      "| qf2_loss                | 9.029769    |\n",
      "| time_elapsed            | 82          |\n",
      "| total timesteps         | 21800       |\n",
      "| value_loss              | 2.1862493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26259053  |\n",
      "| ent_coef_loss           | 0.022384286 |\n",
      "| entropy                 | 0.20759566  |\n",
      "| episodes                | 120         |\n",
      "| fps                     | 265         |\n",
      "| mean 100 episode reward | -536        |\n",
      "| n_updates               | 23700       |\n",
      "| policy_loss             | 189.10211   |\n",
      "| qf1_loss                | 9.4417095   |\n",
      "| qf2_loss                | 7.507381    |\n",
      "| time_elapsed            | 89          |\n",
      "| total timesteps         | 23800       |\n",
      "| value_loss              | 1.4276142   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.2772483   |\n",
      "| ent_coef_loss           | 0.081394166 |\n",
      "| entropy                 | 0.37311614  |\n",
      "| episodes                | 130         |\n",
      "| fps                     | 266         |\n",
      "| mean 100 episode reward | -425        |\n",
      "| n_updates               | 25700       |\n",
      "| policy_loss             | 180.288     |\n",
      "| qf1_loss                | 44.55269    |\n",
      "| qf2_loss                | 40.950188   |\n",
      "| time_elapsed            | 96          |\n",
      "| total timesteps         | 25800       |\n",
      "| value_loss              | 2.1106424   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.31641117  |\n",
      "| ent_coef_loss           | -0.23995584 |\n",
      "| entropy                 | 0.4946065   |\n",
      "| episodes                | 140         |\n",
      "| fps                     | 267         |\n",
      "| mean 100 episode reward | -312        |\n",
      "| n_updates               | 27700       |\n",
      "| policy_loss             | 179.8356    |\n",
      "| qf1_loss                | 17.563026   |\n",
      "| qf2_loss                | 14.885075   |\n",
      "| time_elapsed            | 103         |\n",
      "| total timesteps         | 27800       |\n",
      "| value_loss              | 2.9040422   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26897702  |\n",
      "| ent_coef_loss           | -0.30434984 |\n",
      "| entropy                 | 0.3203676   |\n",
      "| episodes                | 150         |\n",
      "| fps                     | 268         |\n",
      "| mean 100 episode reward | -271        |\n",
      "| n_updates               | 29700       |\n",
      "| policy_loss             | 141.42816   |\n",
      "| qf1_loss                | 9.073522    |\n",
      "| qf2_loss                | 10.091218   |\n",
      "| time_elapsed            | 111         |\n",
      "| total timesteps         | 29800       |\n",
      "| value_loss              | 1.0258338   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.22823386   |\n",
      "| ent_coef_loss           | -0.023934528 |\n",
      "| entropy                 | 0.46155518   |\n",
      "| episodes                | 160          |\n",
      "| fps                     | 269          |\n",
      "| mean 100 episode reward | -266         |\n",
      "| n_updates               | 31700        |\n",
      "| policy_loss             | 131.14703    |\n",
      "| qf1_loss                | 35.414974    |\n",
      "| qf2_loss                | 29.211351    |\n",
      "| time_elapsed            | 118          |\n",
      "| total timesteps         | 31800        |\n",
      "| value_loss              | 4.3084717    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.22835274  |\n",
      "| ent_coef_loss           | -0.41216263 |\n",
      "| entropy                 | 0.47278962  |\n",
      "| episodes                | 170         |\n",
      "| fps                     | 269         |\n",
      "| mean 100 episode reward | -240        |\n",
      "| n_updates               | 33700       |\n",
      "| policy_loss             | 132.45137   |\n",
      "| qf1_loss                | 8.512825    |\n",
      "| qf2_loss                | 10.170343   |\n",
      "| time_elapsed            | 125         |\n",
      "| total timesteps         | 33800       |\n",
      "| value_loss              | 4.0674286   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.22831234  |\n",
      "| ent_coef_loss           | 0.048715636 |\n",
      "| entropy                 | 0.21033294  |\n",
      "| episodes                | 180         |\n",
      "| fps                     | 270         |\n",
      "| mean 100 episode reward | -209        |\n",
      "| n_updates               | 35700       |\n",
      "| policy_loss             | 118.92027   |\n",
      "| qf1_loss                | 19.699804   |\n",
      "| qf2_loss                | 15.309666   |\n",
      "| time_elapsed            | 132         |\n",
      "| total timesteps         | 35800       |\n",
      "| value_loss              | 4.357376    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2436631  |\n",
      "| ent_coef_loss           | 0.43905145 |\n",
      "| entropy                 | 0.22147574 |\n",
      "| episodes                | 190        |\n",
      "| fps                     | 270        |\n",
      "| mean 100 episode reward | -196       |\n",
      "| n_updates               | 37700      |\n",
      "| policy_loss             | 106.18643  |\n",
      "| qf1_loss                | 12.238468  |\n",
      "| qf2_loss                | 8.3349085  |\n",
      "| time_elapsed            | 139        |\n",
      "| total timesteps         | 37800      |\n",
      "| value_loss              | 5.1727896  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.23377925 |\n",
      "| ent_coef_loss           | 0.47738314 |\n",
      "| entropy                 | 0.27453083 |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 271        |\n",
      "| mean 100 episode reward | -179       |\n",
      "| n_updates               | 39700      |\n",
      "| policy_loss             | 113.4449   |\n",
      "| qf1_loss                | 14.8471155 |\n",
      "| qf2_loss                | 15.22937   |\n",
      "| time_elapsed            | 146        |\n",
      "| total timesteps         | 39800      |\n",
      "| value_loss              | 4.491402   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2350317  |\n",
      "| ent_coef_loss           | -0.1967774 |\n",
      "| entropy                 | 0.18286443 |\n",
      "| episodes                | 210        |\n",
      "| fps                     | 271        |\n",
      "| mean 100 episode reward | -178       |\n",
      "| n_updates               | 41700      |\n",
      "| policy_loss             | 67.83449   |\n",
      "| qf1_loss                | 10.8597355 |\n",
      "| qf2_loss                | 8.859592   |\n",
      "| time_elapsed            | 153        |\n",
      "| total timesteps         | 41800      |\n",
      "| value_loss              | 5.2727594  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.21734853  |\n",
      "| ent_coef_loss           | -0.11129843 |\n",
      "| entropy                 | 0.17172334  |\n",
      "| episodes                | 220         |\n",
      "| fps                     | 272         |\n",
      "| mean 100 episode reward | -165        |\n",
      "| n_updates               | 43700       |\n",
      "| policy_loss             | 65.13429    |\n",
      "| qf1_loss                | 10.77186    |\n",
      "| qf2_loss                | 12.8613405  |\n",
      "| time_elapsed            | 160         |\n",
      "| total timesteps         | 43800       |\n",
      "| value_loss              | 4.6887193   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.20461977   |\n",
      "| ent_coef_loss           | 0.0017534234 |\n",
      "| entropy                 | 0.12787107   |\n",
      "| episodes                | 230          |\n",
      "| fps                     | 273          |\n",
      "| mean 100 episode reward | -160         |\n",
      "| n_updates               | 45700        |\n",
      "| policy_loss             | 57.42298     |\n",
      "| qf1_loss                | 8.965583     |\n",
      "| qf2_loss                | 7.554147     |\n",
      "| time_elapsed            | 167          |\n",
      "| total timesteps         | 45800        |\n",
      "| value_loss              | 2.0051694    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18127663 |\n",
      "| ent_coef_loss           | 0.4600265  |\n",
      "| entropy                 | 0.28365088 |\n",
      "| episodes                | 240        |\n",
      "| fps                     | 273        |\n",
      "| mean 100 episode reward | -150       |\n",
      "| n_updates               | 47700      |\n",
      "| policy_loss             | 73.73108   |\n",
      "| qf1_loss                | 487.0581   |\n",
      "| qf2_loss                | 502.2468   |\n",
      "| time_elapsed            | 174        |\n",
      "| total timesteps         | 47800      |\n",
      "| value_loss              | 2.5175054  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.16792445  |\n",
      "| ent_coef_loss           | -0.15558341 |\n",
      "| entropy                 | 0.13739406  |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 274         |\n",
      "| mean 100 episode reward | -148        |\n",
      "| n_updates               | 49700       |\n",
      "| policy_loss             | 52.02412    |\n",
      "| qf1_loss                | 10.707564   |\n",
      "| qf2_loss                | 10.744356   |\n",
      "| time_elapsed            | 181         |\n",
      "| total timesteps         | 49800       |\n",
      "| value_loss              | 2.904112    |\n",
      "-----------------------------------------\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "env = gym.make('Pendulum-v0')\n",
    "\n",
    "model = SAC(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=50000, log_interval=10)\n",
    "model.save(\"sac_pendulum\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = SAC.load(\"sac_pendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stable Baselines (3.6)",
   "language": "python",
   "name": "stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
