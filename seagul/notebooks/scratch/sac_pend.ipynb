{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sgillen/work/seagul/seagul/rl/algos/__init__.py:9: UserWarning: tensorflow not installed, skipping symmetric ppo\n",
      "  warnings.warn(\"tensorflow not installed, skipping symmetric ppo\")\n",
      "/Users/sgillen/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4800/20000 [00:54<03:18, 76.46it/s]\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 15.3 s, total: 2min 54s\n",
      "Wall time: 1min\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 800/20000 [00:00<00:06, 3054.04it/s]\u001b[A\n",
      " 24%|██▍       | 4800/20000 [01:10<03:18, 76.46it/s]\n",
      "  8%|▊         | 1600/20000 [00:11<02:17, 133.79it/s]\u001b[A\n",
      " 10%|█         | 2000/20000 [00:17<02:45, 108.73it/s]\u001b[A\n",
      " 12%|█▏        | 2400/20000 [00:24<03:27, 84.94it/s] \u001b[A\n",
      " 14%|█▍        | 2800/20000 [00:31<03:53, 73.77it/s]\u001b[A\n",
      " 16%|█▌        | 3200/20000 [00:36<03:47, 73.91it/s]\u001b[A\n",
      " 18%|█▊        | 3600/20000 [00:42<03:42, 73.72it/s]\u001b[A\n",
      " 20%|██        | 4000/20000 [00:47<03:35, 74.22it/s]\u001b[A\n",
      " 22%|██▏       | 4400/20000 [00:52<03:30, 74.21it/s]\u001b[A\n",
      " 24%|██▍       | 4800/20000 [00:58<03:24, 74.28it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 16.9 s, total: 2min 59s\n",
      "Wall time: 1min 3s\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 800/20000 [00:00<00:06, 3030.98it/s]\u001b[A\u001b[A\n",
      " 24%|██▍       | 4800/20000 [01:10<03:24, 74.28it/s]\u001b[A\n",
      "\n",
      "  6%|▌         | 1200/20000 [00:06<01:34, 199.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 1600/20000 [00:11<02:17, 133.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 2000/20000 [00:17<02:46, 108.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.1 s, sys: 5.87 s, total: 1min 3s\n",
      "Wall time: 22.4 s\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 800/20000 [00:00<00:06, 3046.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 1200/20000 [00:05<01:18, 238.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 1600/20000 [00:10<02:06, 145.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 2000/20000 [00:36<02:46, 108.20it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.8 s, sys: 4.06 s, total: 46.9 s\n",
      "Wall time: 15.9 s\n",
      "CPU times: user 7min 3s, sys: 42.3 s, total: 7min 45s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from seagul.rl.algos import sac, ppo\n",
    "#from seagul.rl.algos.sac_ray import ray_sac\n",
    "from seagul.rl.algos.sac_sym import sac_sym\n",
    "from seagul.nn import MLP\n",
    "from seagul.rl.models import SACModel, PPOModel \n",
    "\n",
    "input_size = 3\n",
    "output_size = 1\n",
    "layer_size = 64\n",
    "num_layers = 2\n",
    "\n",
    "policy = MLP(input_size, output_size*2, num_layers, layer_size)\n",
    "value_fn = MLP(input_size, 1, num_layers, layer_size)\n",
    "q1_fn = MLP(input_size + output_size, 1, num_layers, layer_size)\n",
    "q2_fn = MLP(input_size + output_size, 1, num_layers, layer_size)\n",
    "model = SACModel(policy, value_fn, q1_fn, q2_fn, 3)\n",
    "\n",
    "\n",
    "ppo_policy = MLP(input_size, output_size, num_layers, layer_size)\n",
    "ppo_model = PPOModel(ppo_policy, value_fn)\n",
    "\n",
    "env_name = \"Pendulum-v0\"\n",
    "#model, rews, var_dict = ray_sac(env_name, 20000, model, env_steps=0, iters_per_update=100, min_steps_per_update=100, reward_stop=-200, exploration_steps=100)\n",
    "#model, rews, var_dict = ppo(env_name, 3e5, ppo_model)\n",
    "\n",
    "for seed in [0,1,2,3]:\n",
    "    %time model, rews, var_dict = sac_sym(env_name, 20000, model, seed=seed, env_steps=0, iters_per_update=100, min_steps_per_update=100, reward_stop=-200, exploration_steps=100)\n",
    "\n",
    "\n",
    "for seed in [0,1,2,3]:\n",
    "    %time model, rews, var_dict = sac(env_name, 20000, model, seed=seed, env_steps=0, iters_per_update=100, min_steps_per_update=100, reward_stop=-200, exploration_steps=100)\n",
    "\n",
    "\n",
    "globals().update(var_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(raw_rew_hist)\n",
    "plt.figure()\n",
    "plt.plot(pol_loss_hist)\n",
    "plt.figure()\n",
    "plt.plot(val_loss_hist)\n",
    "plt.figure()\n",
    "plt.plot(q1_loss_hist)\n",
    "plt.plot(q2_loss_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_obs1, replay_obs2, replay_acts, replay_rews, replay_done = replay_buf.sample_batch(replay_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buf.sample_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "env = gym.make(env_name)\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n",
    "obs_list = []\n",
    "act_list = []\n",
    "rew_list = []\n",
    "avg_list = []\n",
    "val_list = []\n",
    "\n",
    " \n",
    "dtype = torch.float32\n",
    "act_size = env.action_space.shape[0]\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    model_obs = torch.as_tensor(obs, dtype=dtype).detach() #TODO.... (or not, this still works with ppo right??)\n",
    "    obs_list.append(obs)\n",
    "    \n",
    "    noise = torch.randn(act_size)\n",
    "    act, logp = model.select_action(model_obs.reshape(1, -1), noise)\n",
    "    act = act.detach()\n",
    "\n",
    "    obs, rew, done, _ = env.step(act.numpy().reshape(-1))\n",
    "    env.render()\n",
    "\n",
    "    act_list.append(act)\n",
    "    rew_list.append(rew)\n",
    "\n",
    "print(sum(rew_list))\n",
    "plt.plot(obs_list)\n",
    "plt.figure()\n",
    "plt.plot(act_list)\n",
    "plt.figure()\n",
    "plt.plot(rew_list)\n",
    "plt.figure()\n",
    "plt.plot(val_list)\n",
    "plt.figure()\n",
    "plt.plot(avg_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
