{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sgillen/anaconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/sgillen/anaconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/sgillen/anaconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/sgillen/anaconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/sgillen/anaconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/sgillen/anaconda3/envs/ray/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2020-01-13 12:43:49,053\tWARNING worker.py:1426 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2020-01-13 12:43:49,058\tINFO resource_spec.py:205 -- Starting Ray with 4.1 GiB memory available for workers and up to 2.05 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "  0%|          | 0/20000 [00:00<?, ?it/s]2020-01-13 12:43:49,717\tWARNING worker.py:352 -- WARNING: Falling back to serializing objects of type <class 'numpy.dtype'> by using pickle. This may be inefficient.\n",
      "2020-01-13 12:43:49,728\tWARNING worker.py:352 -- WARNING: Falling back to serializing objects of type <class 'numpy.random.mtrand.RandomState'> by using pickle. This may be inefficient.\n",
      " 30%|███       | 6000/20000 [01:43<04:46, 48.90it/s]"
     ]
    }
   ],
   "source": [
    "from seagul.rl.algos import sac, ppo\n",
    "from seagul.rl.algos.sac_ray import ray_sac\n",
    "from seagul.rl.algos.sac_sym import sac_sym\n",
    "from seagul.nn import MLP\n",
    "from seagul.rl.models import SACModel, PPOModel \n",
    "\n",
    "input_size = 3\n",
    "output_size = 1\n",
    "layer_size = 64\n",
    "num_layers = 2\n",
    "\n",
    "policy = MLP(input_size, output_size*2, num_layers, layer_size)\n",
    "value_fn = MLP(input_size, 1, num_layers, layer_size)\n",
    "q1_fn = MLP(input_size + output_size, 1, num_layers, layer_size)\n",
    "q2_fn = MLP(input_size + output_size, 1, num_layers, layer_size)\n",
    "model = SACModel(policy, value_fn, q1_fn, q2_fn, 3)\n",
    "\n",
    "\n",
    "ppo_policy = MLP(input_size, output_size, num_layers, layer_size)\n",
    "ppo_model = PPOModel(ppo_policy, value_fn)\n",
    "\n",
    "env_name = \"Pendulum-v0\"\n",
    "model, rews, var_dict = ray_sac(env_name, 20000, model, env_steps=0, iters_per_update=100, min_steps_per_update=100, reward_stop=-200, exploration_steps=100)\n",
    "#model, rews, var_dict = ppo(env_name, 3e5, ppo_model)\n",
    "\n",
    "for seed in [0,1,2,3]:\n",
    "    %time model, rews, var_dict = sac_sym(env_name, 20000, model, num_envs = 15, seed=seed, env_steps=0, iters_per_update=100, min_steps_per_update=100, reward_stop=-200, exploration_steps=100)\n",
    "\n",
    "\n",
    "for seed in [0,1,2,3]:\n",
    "    %time model, rews, var_dict = sac(env_name, 20000, model, seed=seed, env_steps=0, iters_per_update=100, min_steps_per_update=100, reward_stop=-200, exploration_steps=100)\n",
    "\n",
    "\n",
    "globals().update(var_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(raw_rew_hist)\n",
    "plt.figure()\n",
    "plt.plot(pol_loss_hist)\n",
    "plt.figure()\n",
    "plt.plot(val_loss_hist)\n",
    "plt.figure()\n",
    "plt.plot(q1_loss_hist)\n",
    "plt.plot(q2_loss_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_obs1, replay_obs2, replay_acts, replay_rews, replay_done = replay_buf.sample_batch(replay_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buf.sample_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "env = gym.make(env_name)\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n",
    "obs_list = []\n",
    "act_list = []\n",
    "rew_list = []\n",
    "avg_list = []\n",
    "val_list = []\n",
    "\n",
    " \n",
    "dtype = torch.float32\n",
    "act_size = env.action_space.shape[0]\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    model_obs = torch.as_tensor(obs, dtype=dtype).detach() #TODO.... (or not, this still works with ppo right??)\n",
    "    obs_list.append(obs)\n",
    "    \n",
    "    noise = torch.randn(act_size)\n",
    "    act, logp = model.select_action(model_obs.reshape(1, -1), noise)\n",
    "    act = act.detach()\n",
    "\n",
    "    obs, rew, done, _ = env.step(act.numpy().reshape(-1))\n",
    "    env.render()\n",
    "\n",
    "    act_list.append(act)\n",
    "    rew_list.append(rew)\n",
    "\n",
    "print(sum(rew_list))\n",
    "plt.plot(obs_list)\n",
    "plt.figure()\n",
    "plt.plot(act_list)\n",
    "plt.figure()\n",
    "plt.plot(rew_list)\n",
    "plt.figure()\n",
    "plt.plot(val_list)\n",
    "plt.figure()\n",
    "plt.plot(avg_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ray (3.6)",
   "language": "python",
   "name": "ray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
